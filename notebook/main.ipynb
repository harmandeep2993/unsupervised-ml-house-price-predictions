{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add559f9",
   "metadata": {},
   "source": [
    "# project title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a70505",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9f7d64",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3944575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d99869",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e47f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"..\\dataset\\king_ country_ houses_aa.csv\"\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d4c1f",
   "metadata": {},
   "source": [
    "### Column rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76bf526",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "\n",
    "# Loop through each column name of the DataFrame\n",
    "for col in list(df.columns):\n",
    "    new_col = col.strip().lower().replace(\" \", \"_\")\n",
    "    new_cols.append(new_col)\n",
    "\n",
    "# Reassign the column names to DataFrame \n",
    "df.columns = new_cols\n",
    "\n",
    "# Confirm changes\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = {\n",
    "    'id': 'A unique identifier for a house',\n",
    "    'date': 'The date on which the house was sold',\n",
    "    'price': 'The sale price of the house (prediction target)',\n",
    "    'bedrooms': 'Number of bedrooms in the house',\n",
    "    'bathrooms': 'Number of bathrooms in the house, per bedroom',\n",
    "    'sqft_living': 'Square footage of the interior living space',\n",
    "    'sqft_lot': 'Square footage of the land space',\n",
    "    'floors': 'Number of floors (levels) in the house',\n",
    "    'waterfront': 'Whether the house has a waterfront view',\n",
    "    'view': 'Number of times the house has been viewed',\n",
    "    'condition': 'The overall condition of the house',\n",
    "    'grade': 'The overall grade given to the house, based on the King County grading system',\n",
    "    'sqft_above': 'Square footage of the house apart from the basement',\n",
    "    'sqft_basement': 'Square footage of the basement',\n",
    "    'yr_built': 'The year the house was built',\n",
    "    'yr_renovated': 'The year the house was renovated',\n",
    "    'zipcode': 'ZIP code area',\n",
    "    'lat': 'Latitude coordinate',\n",
    "    'long': 'Longitude coordinate',\n",
    "    'sqft_living15': 'The interior living space for the nearest 15 neighbors in 2015',\n",
    "    'sqft_lot15': 'The land spaces for the nearest 15 neighbors in 2015'\n",
    "}\n",
    "def all_cols_descrition():\n",
    "    return description\n",
    "\n",
    "def col_description(col_name):\n",
    "     print(description[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe28470",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_description('sqft_lot15')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b8f29",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca00d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db185756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = df.date.astype('object')\n",
    "print(df.date.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87c4e0",
   "metadata": {},
   "source": [
    "### Duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a32f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_records(datafame):\n",
    "    duplicate_count = datafame.duplicated().sum()\n",
    "\n",
    "    if duplicate_count == 0:\n",
    "        print(f\"No duplicate records found: {duplicate_count}\")\n",
    "    else:\n",
    "        print(f\"The dataset has duplicate records: {duplicate_count}\")\n",
    "\n",
    "duplicate_records(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac607a1",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d07756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(dataframe):\n",
    "    missing_count = dataframe.isna().sum()\n",
    "    total_missing_count = missing_count.sum()\n",
    "\n",
    "    if total_missing_count == 0:\n",
    "        print(f\"No missing values found in the dataset\")\n",
    "        return  missing_count\n",
    "    else:\n",
    "        print(f\"Missing values found in the dataset\")\n",
    "        return missing_count\n",
    "    \n",
    "missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8427be6",
   "metadata": {},
   "source": [
    "Question: What we can remove for first baseline model?\n",
    "- Since we checked our data already and we can donot have missing values and duplicate records.\n",
    "\n",
    "- But we have ``id`` and ``date`` column which we can drop fro our first baseline model.\n",
    "\n",
    "After baseline model\n",
    "- Column ``bedrooms`` has max value of 33 Bedrooms. But  75% of the data has lies with 4 number of rooms.\n",
    "\n",
    "- Treat columns  ``zipcode``, ``lat`` and ``long``. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc971c",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e5343",
   "metadata": {},
   "source": [
    "### Baseline Model (version_0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2971d9e",
   "metadata": {},
   "source": [
    "- This baseline model is based on the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline = df.drop(columns=['id', 'date'])\n",
    "df_baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715293d",
   "metadata": {},
   "source": [
    "#### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3629d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_baseline.drop(columns=['price']) \n",
    "y = df_baseline['price']\n",
    "\n",
    "print(f\"Total feature shape: {X.shape}\")\n",
    "print(f\"Target feature shape: {y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=45)\n",
    "\n",
    "print(f\"X_train size: {X_train.shape}\")\n",
    "print(f\"X_test size: {X_test.shape}\")\n",
    "print(f\"y_train size: {y_train.shape}\")\n",
    "print(f\"y_test size: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d5930",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilise the baseline model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the data\n",
    "lr_baseline_model = lr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_test = lr_baseline_model.predict(X_test)\n",
    "y_pred_train = lr_baseline_model.predict(X_train)\n",
    "\n",
    "print(len(y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9117e",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96034374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2\n",
    "r2_train_baseline = r2_score(y_train, y_pred_train)\n",
    "r2_test_baseline = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# RMSE\n",
    "rmse_train_baseline = root_mean_squared_error(y_train, y_pred_train)\n",
    "rmse_test_baseline = root_mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(\"R2 Score\")\n",
    "print(f\"R2 score train: {r2_train_baseline:.2f}\")\n",
    "print(f\"R2 score test: {r2_test_baseline:.2f}\")\n",
    "\n",
    "print(\"\\nRMSE Score\")\n",
    "print(f\"RMSE train : {rmse_train_baseline:.2f}\")\n",
    "print(f\"RMSE test : {rmse_test_baseline:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482ad08",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "- Model is stable, no sign of ovrfitting. \n",
    "\n",
    "- Model explains 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485a886",
   "metadata": {},
   "source": [
    "### Scaled Model (version_0.1)\n",
    "- We implement the scaling on the dataset that we have used to train the baseline model.\n",
    "\n",
    "- After scaling we train the model again on the scaled dataset and observe any changes in model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105df584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(ytrain, ytrainpred, ytest,  ytestpred, step):\n",
    "\n",
    "    # R2\n",
    "    r2_train = r2_score(ytrain, ytrainpred)\n",
    "    r2_test = r2_score(ytest, ytestpred)\n",
    "\n",
    "    # RMSE\n",
    "    rmse_train = root_mean_squared_error(ytrain, ytrainpred)\n",
    "    rmse_test = root_mean_squared_error(ytest, ytestpred)\n",
    "\n",
    "    print(f\"R2 Score {step}\")\n",
    "    print(f\"R2 score train: {r2_train:.2f}\")\n",
    "    print(f\"R2 score test: {r2_test:.2f}\")\n",
    "\n",
    "    print(f\"\\nRMSE Score {step}\")\n",
    "    print(f\"RMSE train : {rmse_train:.2f}\")\n",
    "    print(f\"RMSE test : {rmse_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d78322c",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903bd627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda7f4e",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model with scaled dataset\n",
    "lr_baseline_model_scaled = lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_scaled = lr_baseline_model_scaled.predict(X_train_scaled)\n",
    "y_test_pred_scaled = lr_baseline_model_scaled.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f176f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dada3140",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(y_train, y_train_pred_scaled, y_test, y_test_pred_scaled, 'scaled')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
